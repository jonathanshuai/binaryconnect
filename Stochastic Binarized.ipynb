{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Connect Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, Function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 1000\n",
    "validation_steps = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=True, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5,), (0.5,))\n",
    "                       ])), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, \n",
    "                        transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5,), (0.5,))\n",
    "                       ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binarize(Function):\n",
    "    def __init__(self, fc):\n",
    "        super(Binarize, self).__init__()\n",
    "        self.fc = fc\n",
    "\n",
    "    @staticmethod        \n",
    "    def forward(ctx, input, weight, bias):\n",
    "        p_weight = torch.max(torch.zeros_like(weight), torch.min(torch.ones_like(weight), (weight + 1) / 2))\n",
    "        binarized_weights = torch.bernoulli(p_weight) * 2 - 1\n",
    "\n",
    "        output = F.linear(input, binarized_weights, bias)\n",
    "        ctx.save_for_backward(input, binarized_weights, bias)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    @staticmethod    \n",
    "    def backward(ctx, gradients):\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        grad_input = None\n",
    "        grad_weight = None\n",
    "        grad_bias = None\n",
    "\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = gradients.mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = gradients.t().mm(input)\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = gradients.sum(0)\n",
    "\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "    \n",
    "class BinarizedLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(BinarizedLinear, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "   \n",
    "    def forward(self, input):\n",
    "        output = Binarize.apply(input, self.fc.weight, self.fc.bias)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizedDNNModel(nn.Module):\n",
    "    def __init__(self, image_size, output_size=10, hidden_size=1024):\n",
    "        super(BinarizedDNNModel, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "                   BinarizedLinear(image_size * image_size, hidden_size),\n",
    "                   nn.ReLU(),\n",
    "                   nn.BatchNorm1d(hidden_size))\n",
    "        self.fc2 = nn.Sequential(\n",
    "                   BinarizedLinear(hidden_size, hidden_size),\n",
    "                   nn.ReLU(),\n",
    "                   nn.BatchNorm1d(hidden_size))\n",
    "        self.fc3 = nn.Sequential(\n",
    "                   BinarizedLinear(hidden_size, hidden_size),\n",
    "                   nn.ReLU(),\n",
    "                   nn.BatchNorm1d(hidden_size))\n",
    "        self.output_layer = nn.Sequential(\n",
    "                    BinarizedLinear(hidden_size, output_size),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(output_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.image_size * self.image_size)\n",
    "        \n",
    "        for layer in [self.fc1, self.fc2, self.fc3, self.output_layer]:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class L2SVMLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L2SVMLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        y = one_hot_encoding(target)\n",
    "        ot = output * y\n",
    "        loss = torch.mean(torch.pow(F.relu(1 - ot), 2))\n",
    "        return loss\n",
    "    \n",
    "def one_hot_encoding(labels):\n",
    "    y = torch.eye(10) * 2 - 1\n",
    "    return y[labels].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinarizedDNNModel(image_size=28).to(device)\n",
    "loss_function = L2SVMLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "========[EPOCH 0/25]========\n",
      "[TRAIN ACCURACY]: 0.0998\n",
      "[TRAIN LOSS]: 862.1163\n",
      "[VALIDATION ACCURACY]: 0.0969\n",
      "========[EPOCH 1/25]========\n",
      "[TRAIN ACCURACY]: 0.0985\n",
      "[TRAIN LOSS]: 749.5421\n",
      "========[EPOCH 2/25]========\n",
      "[TRAIN ACCURACY]: 0.0971\n",
      "[TRAIN LOSS]: 654.3454\n",
      "========[EPOCH 3/25]========\n",
      "[TRAIN ACCURACY]: 0.0998\n",
      "[TRAIN LOSS]: 572.3595\n",
      "========[EPOCH 4/25]========\n",
      "[TRAIN ACCURACY]: 0.0992\n",
      "[TRAIN LOSS]: 503.9327\n",
      "========[EPOCH 5/25]========\n",
      "[TRAIN ACCURACY]: 0.0998\n",
      "[TRAIN LOSS]: 448.6664\n",
      "========[EPOCH 6/25]========\n",
      "[TRAIN ACCURACY]: 0.1025\n",
      "[TRAIN LOSS]: 399.8993\n",
      "========[EPOCH 7/25]========\n",
      "[TRAIN ACCURACY]: 0.0989\n",
      "[TRAIN LOSS]: 361.7178\n",
      "========[EPOCH 8/25]========\n",
      "[TRAIN ACCURACY]: 0.0996\n",
      "[TRAIN LOSS]: 328.7515\n",
      "========[EPOCH 9/25]========\n",
      "[TRAIN ACCURACY]: 0.0984\n",
      "[TRAIN LOSS]: 301.3917\n",
      "========[EPOCH 10/25]========\n",
      "[TRAIN ACCURACY]: 0.1027\n",
      "[TRAIN LOSS]: 278.3635\n",
      "[VALIDATION ACCURACY]: 0.1002\n",
      "========[EPOCH 11/25]========\n",
      "[TRAIN ACCURACY]: 0.1014\n",
      "[TRAIN LOSS]: 259.2869\n",
      "========[EPOCH 12/25]========\n",
      "[TRAIN ACCURACY]: 0.1007\n",
      "[TRAIN LOSS]: 244.1518\n",
      "========[EPOCH 13/25]========\n",
      "[TRAIN ACCURACY]: 0.0990\n",
      "[TRAIN LOSS]: 231.7206\n",
      "========[EPOCH 14/25]========\n",
      "[TRAIN ACCURACY]: 0.1003\n",
      "[TRAIN LOSS]: 220.8278\n",
      "========[EPOCH 15/25]========\n",
      "[TRAIN ACCURACY]: 0.0995\n",
      "[TRAIN LOSS]: 211.8602\n",
      "========[EPOCH 16/25]========\n",
      "[TRAIN ACCURACY]: 0.0985\n",
      "[TRAIN LOSS]: 204.7760\n",
      "========[EPOCH 17/25]========\n",
      "[TRAIN ACCURACY]: 0.1021\n",
      "[TRAIN LOSS]: 197.9800\n",
      "========[EPOCH 18/25]========\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"========[EPOCH {}/{}]========\".format(epoch, n_epochs))\n",
    "    \n",
    "    # Training\n",
    "    train_acc = 0\n",
    "    train_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.data.cpu().numpy()\n",
    "        train_acc += np.mean(torch.argmax(outputs, 1).data.cpu().numpy() == labels.data.cpu().numpy())\n",
    "\n",
    "    train_acc = train_acc / len(train_loader)\n",
    "    print(\"[TRAIN ACCURACY]: {:.4f}\".format(train_acc))\n",
    "    print(\"[TRAIN LOSS]: {:.4f}\".format(train_loss))\n",
    "\n",
    "    if epoch % validation_steps == 0:\n",
    "        # Validation\n",
    "        valid_acc = 0\n",
    "        for i, (images, labels) in enumerate(valid_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            valid_acc += np.mean(torch.argmax(outputs, 1).data.cpu().numpy() == labels.data.cpu().numpy())\n",
    "\n",
    "        valid_acc = valid_acc / len(valid_loader)\n",
    "        print(\"[VALIDATION ACCURACY]: {:.4f}\".format(valid_acc))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
