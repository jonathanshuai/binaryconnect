{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Connect Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, Function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 25\n",
    "validation_steps = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=True, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5,), (0.5,))\n",
    "                       ])), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, \n",
    "                        transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5,), (0.5,))\n",
    "                       ])), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binarize(Function):\n",
    "    def __init__(self, fc):\n",
    "        super(Binarize, self).__init__()\n",
    "        self.fc = fc\n",
    "\n",
    "    @staticmethod        \n",
    "    def forward(ctx, input, weight, bias):\n",
    "        p_weight = torch.max(torch.zeros_like(weight), torch.min(torch.ones_like(weight), (weight + 1) / 2))\n",
    "        binarized_weights = torch.bernoulli(p_weight) * 2 - 1\n",
    "\n",
    "        output = F.linear(input, weight, bias)\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "    \n",
    "        return output\n",
    "\n",
    "    @staticmethod    \n",
    "    def backward(ctx, gradients):\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        grad_input = None\n",
    "        grad_weight = None\n",
    "        grad_bias = None\n",
    "\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = gradients.mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = gradients.t().mm(input)\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = gradients.sum(0)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "    \n",
    "class BinarizedLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(BinarizedLinear, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = Binarize.apply(input, self.fc.weight, self.fc.bias)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizedDNNModel(nn.Module):\n",
    "    def __init__(self, image_size, output_size=10, hidden_size=1024):\n",
    "        super(BinarizedDNNModel, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "                   BinarizedLinear(image_size * image_size, hidden_size),\n",
    "                   nn.ReLU(),\n",
    "                   nn.BatchNorm1d(hidden_size))\n",
    "        self.fc2 = nn.Sequential(\n",
    "                   BinarizedLinear(hidden_size, hidden_size),\n",
    "                   nn.ReLU(),\n",
    "                   nn.BatchNorm1d(hidden_size))\n",
    "        self.fc3 = nn.Sequential(\n",
    "                   BinarizedLinear(hidden_size, hidden_size),\n",
    "                   nn.ReLU(),\n",
    "                   nn.BatchNorm1d(hidden_size))\n",
    "        self.output_layer = nn.Sequential(\n",
    "                    BinarizedLinear(hidden_size, output_size),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(output_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.image_size * self.image_size)\n",
    "        \n",
    "        for layer in [self.fc1, self.fc2, self.fc3, self.output_layer]:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class L2SVMLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L2SVMLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        y = one_hot_encoding(target)\n",
    "        ot = output * y\n",
    "        loss = torch.mean(torch.pow(F.relu(1 - ot), 2))\n",
    "        return loss\n",
    "    \n",
    "def one_hot_encoding(labels):\n",
    "    y = torch.eye(10) * 2 - 1\n",
    "    return y[labels].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINARIZED NEW MODEL\n"
     ]
    }
   ],
   "source": [
    "model = BinarizedDNNModel(image_size=28).to(device)\n",
    "loss_function = L2SVMLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "========[EPOCH 0/25]========\n",
      "[TRAIN ACCURACY]: 0.7745\n",
      "[TRAIN LOSS]: 336.6467\n",
      "[VALIDATION ACCURACY]: 0.8721\n",
      "========[EPOCH 1/25]========\n",
      "[TRAIN ACCURACY]: 0.8820\n",
      "[TRAIN LOSS]: 217.2840\n",
      "========[EPOCH 2/25]========\n",
      "[TRAIN ACCURACY]: 0.9021\n",
      "[TRAIN LOSS]: 177.0586\n",
      "========[EPOCH 3/25]========\n",
      "[TRAIN ACCURACY]: 0.9152\n",
      "[TRAIN LOSS]: 147.9012\n",
      "========[EPOCH 4/25]========\n",
      "[TRAIN ACCURACY]: 0.9232\n",
      "[TRAIN LOSS]: 125.2606\n",
      "========[EPOCH 5/25]========\n",
      "[TRAIN ACCURACY]: 0.9288\n",
      "[TRAIN LOSS]: 106.8999\n",
      "========[EPOCH 6/25]========\n",
      "[TRAIN ACCURACY]: 0.9334\n",
      "[TRAIN LOSS]: 92.0358\n",
      "========[EPOCH 7/25]========\n",
      "[TRAIN ACCURACY]: 0.9361\n",
      "[TRAIN LOSS]: 79.8763\n",
      "========[EPOCH 8/25]========\n",
      "[TRAIN ACCURACY]: 0.9408\n",
      "[TRAIN LOSS]: 69.3813\n",
      "========[EPOCH 9/25]========\n",
      "[TRAIN ACCURACY]: 0.9444\n",
      "[TRAIN LOSS]: 60.7310\n",
      "========[EPOCH 10/25]========\n",
      "[TRAIN ACCURACY]: 0.9460\n",
      "[TRAIN LOSS]: 53.8554\n",
      "[VALIDATION ACCURACY]: 0.9394\n",
      "========[EPOCH 11/25]========\n",
      "[TRAIN ACCURACY]: 0.9482\n",
      "[TRAIN LOSS]: 47.8662\n",
      "========[EPOCH 12/25]========\n",
      "[TRAIN ACCURACY]: 0.9502\n",
      "[TRAIN LOSS]: 42.8655\n",
      "========[EPOCH 13/25]========\n",
      "[TRAIN ACCURACY]: 0.9529\n",
      "[TRAIN LOSS]: 38.4202\n",
      "========[EPOCH 14/25]========\n",
      "[TRAIN ACCURACY]: 0.9545\n",
      "[TRAIN LOSS]: 34.7837\n",
      "========[EPOCH 15/25]========\n",
      "[TRAIN ACCURACY]: 0.9567\n",
      "[TRAIN LOSS]: 31.5108\n",
      "========[EPOCH 16/25]========\n",
      "[TRAIN ACCURACY]: 0.9582\n",
      "[TRAIN LOSS]: 29.0028\n",
      "========[EPOCH 17/25]========\n",
      "[TRAIN ACCURACY]: 0.9595\n",
      "[TRAIN LOSS]: 26.7822\n",
      "========[EPOCH 18/25]========\n",
      "[TRAIN ACCURACY]: 0.9609\n",
      "[TRAIN LOSS]: 25.0273\n",
      "========[EPOCH 19/25]========\n",
      "[TRAIN ACCURACY]: 0.9623\n",
      "[TRAIN LOSS]: 23.3592\n",
      "========[EPOCH 20/25]========\n",
      "[TRAIN ACCURACY]: 0.9631\n",
      "[TRAIN LOSS]: 22.1143\n",
      "[VALIDATION ACCURACY]: 0.9481\n",
      "========[EPOCH 21/25]========\n",
      "[TRAIN ACCURACY]: 0.9637\n",
      "[TRAIN LOSS]: 20.7373\n",
      "========[EPOCH 22/25]========\n",
      "[TRAIN ACCURACY]: 0.9656\n",
      "[TRAIN LOSS]: 19.6344\n",
      "========[EPOCH 23/25]========\n",
      "[TRAIN ACCURACY]: 0.9667\n",
      "[TRAIN LOSS]: 18.7275\n",
      "========[EPOCH 24/25]========\n",
      "[TRAIN ACCURACY]: 0.9681\n",
      "[TRAIN LOSS]: 17.7747\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"========[EPOCH {}/{}]========\".format(epoch, n_epochs))\n",
    "    \n",
    "    # Training\n",
    "    train_acc = 0\n",
    "    train_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.data.cpu().numpy()\n",
    "        train_acc += np.mean(torch.argmax(outputs, 1).data.cpu().numpy() == labels.data.cpu().numpy())\n",
    "\n",
    "    train_acc = train_acc / len(train_loader)\n",
    "    print(\"[TRAIN ACCURACY]: {:.4f}\".format(train_acc))\n",
    "    print(\"[TRAIN LOSS]: {:.4f}\".format(train_loss))\n",
    "\n",
    "    if epoch % validation_steps == 0:\n",
    "        # Validation\n",
    "        valid_acc = 0\n",
    "        for i, (images, labels) in enumerate(valid_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            valid_acc += np.mean(torch.argmax(outputs, 1).data.cpu().numpy() == labels.data.cpu().numpy())\n",
    "\n",
    "        valid_acc = valid_acc / len(valid_loader)\n",
    "        print(\"[VALIDATION ACCURACY]: {:.4f}\".format(valid_acc))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
